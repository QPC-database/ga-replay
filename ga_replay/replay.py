import csv, time, requests, os, sys, random, re
from datetime import datetime, timedelta
from collections import OrderedDict

import asyncio
from aiohttp import ClientSession

from ga_replay.analytics import analytics
import config

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)

def _write_itinerary(itinerary, outfile_path):
    """
    Write itinerary to CSV file.
    """
    with open(outfile_path, "wt") as f:
        writer = csv.writer(f)
        writer.writerows(itinerary)
    
def get_itinerary(start, end, sites, outfile_path=None, extra_dimensions=[]):
    """
    Generate a requests itinerary CSV, given a start date, end date, file path
    and extra dimensions.  The itinerary is generated by grabbing the requests
    logged in historical google analytics data between the dates provided.

    This will generate a CSV of format:
        `DATE,HOUR,MINUTE,SITE_DOMAIN,PATH,[extra_dimensions],PAGEVIEWS`

    Args:
        * `start` - `date` - the date for the itinerary to begin
        * `end` - `date` - the date for the itinerary to end
        * `sites` - `iterable` - iterable of site domain strings
        * `outfile_path` - `string` - file path of the CSV to write to
        * `extra_dimensions` - `iterable` - iterable of additional GA dimensions
            to request
    """
    if not outfile_path:
        outfile_path = os.path.join(PROJECT_ROOT, "itineraries", "itinerary.csv")
    site_itineraries = {}
    for site in sites:
        ga_id = config.GA_SITES[site]
        print("**** Grabbing itinerary for %s ****" % site)
        site_itinerary = analytics.get_itinerary(start=start, end=end, 
            ga_id=ga_id, extra_dimensions=extra_dimensions)
        site_itineraries[site] = site_itinerary
        print("**** DONE ****")
    print("**** Flattening site itineraries ****")
    flat_itinerary = []
    for site, itinerary in site_itineraries.items():
        for row in itinerary:
            # Transpose to format:
            # [hour, minute, site, path, extra_dimensions*, pageviews] 
            date_str = "%s %s:%s" % (row[1], row[2], row[3])
            dt = datetime.strptime(date_str, "%Y%m%d %H:%M")
            flat_row = [dt.isoformat(), site, row[0]]
            flat_row.extend(row[4:])
            flat_itinerary.append(flat_row)
    print("**** DONE ****")
    print("**** Sorting itinerary by request time ****")
    flat_itinerary.sort(key=lambda row: row[0])
    print("**** DONE ****")
    print("**** Writing final itinerary ****")
    _write_itinerary(flat_itinerary, outfile_path)
    print("**** DONE ****")

async def dummy_request(domain, path, extra_dimensions=[]):
    """
    """
    print("Requesting %s %s %s" % (domain, path, extra_dimensions))

async def simple_request(domain, path, extra_dimensions):
    """
    Simply re-run the request against the same domain/path.
    """
    url = "http://%s%s" % (domain, path)
    async with ClientSession() as session:
        async with session.get(url) as response:
            response = await response.read()

def _get_analytics_section_eurogamer(path):
    if path.startswith('/articles'):
        return 'article'
    if path.startswith('/jobs'):
        return 'jobs'
    if path.startswith('/forum'):
        return 'forum'
    if path.startswith('/user'):
        return 'user'
    if path.startswith('/search'):
        return 'search'
    if path.startswith('/games'):
        return 'game'
    if path.startswith("/profiles") or path.startswith("/inbox"):
        return 'community'
    return "archive"

def _get_analytics_section_nlife(path):
    if path.startswith('/news') or path.startswith('/reviews'):
        return 'article'
    if path.startswith('/forum'):
        return 'forum'
    if path.startswith('/games'):
        return 'game'
    return 'archive'

def _get_analytics_section_prima(path):
    if re.match("^/games/[-\w]+/[-\w]+/[-\w]+$", path):
        return "article"
    if re.match("^/games/[-\w]+/guides", path):
        return "guide"
    if path.startswith('/shop'):
        return 'shop'
    if path.startswith('/account'):
        return 'community'
    if path.startswith('/games'):
        return 'game'
    return 'archive'

def _get_analytics_section_wordpress(path):
    if re.match("^/[0-9]{4}/[0-9]{2}/[0-9]{2}/.+", path):
        return "article"
    return 'archive'

def _get_analytics_section(path, domain):
    if domain.startswith('eurogamer') or domain.startswith('usgamer') or \
            domain.startswith('gamesindustry'):
        return _get_analytics_section_eurogamer(path)
    if domain.startswith('nintendolife'):
        return _get_analytics_section_nlife(path)
    if domain.startswith('prima'):
        return _get_analytics_section_prima(path)
    if domain.startswith('rockpapershotgun') or domain.startswith('vg247'):
        return _get_analytics_section_wordpress(path)

async def analytics_request(domain, path, extra_dimensions=[]):
    """
    Call an analytics endpoint, expects extra_dimensions to contain a referrer.
    """
    analytics_host = config.ANALYTICS_HOST
    section = _get_analytics_section(path, domain)
    data = {
        'path': path, 'site': domain, 'referrer': extra_dimensions[0], 'section': section
    }
    url = "http://%s/record_pageview/" % analytics_host
    async with ClientSession() as session:
        async with session.post(url, data=data) as response:
            response = await response.read()

async def run_request(request_func, request, seconds=59):
    """
    """
    random_delay = random.random() * seconds
    await asyncio.sleep(random_delay)
    try:
        result = await request_func(domain=request[1], path=request[2], extra_dimensions=request[3:-1])
    except (Exception, e):
        print("X", end="")
        sys.stdout.flush()
        return
    print(".", end="")
    sys.stdout.flush()

REQUEST_FUNCTIONS = {
    "dummy": dummy_request,
    "simple": simple_request,
    "analytics": analytics_request,
}

def _load_itinerary(itinerary_path):
    """
    Given a path to an itinerary CSV, load it in to an OrderedDict of format:

    `{
        "2017-06-31T22:00:00": {
            "timestamp": "2017-06-31T22:00",
            "itinerary": [
                ["17", "00", "eurogamer.net", "/", "(direct)", 10],
                ...
            ],
            "total_pageviews": 600,
        }
    }`

    Each row in the itinerary list is a single request to call.
    """
    flat_itinerary = []
    with open(itinerary_path, "rt") as f:
        reader = csv.reader(f)
        flat_itinerary = list(reader)
    itinerary = OrderedDict({})
    for row in flat_itinerary:
        key = row[0]
        pageviews = int(row[-1])
        try:
            itinerary[key]['itinerary'].extend([row] * pageviews)
            itinerary[key]['total_pageviews'] += pageviews
        except KeyError:
            itinerary[key] = {
                'itinerary': [row] * pageviews, 
                'timestamp': row[0], 
                'total_pageviews': pageviews
            }
    return itinerary

loop = asyncio.get_event_loop()

def _get_datetime(timestamp):
    return datetime.strptime(timestamp, "%Y-%m-%dT%H:%M:00")

def simulate_from_itinerary(itinerary_path, request_func=dummy_request, start_time=None):
    """
    Run the network requests in a given itinerary to replay traffic.

    Args:
        * `itinerary_path` - `string` - the path to the itinerary CSV file to replay
        * `[request_func]` - `function` - the function to use when making a request
        * `[start_time]` - `string` - string of format "YYYY-MM-DDTHH:MM:00" to indicate 
            what timestamp to start replaying the itinerary from
    """
    itinerary = _load_itinerary(itinerary_path)
    all_itinerary_timestamps = list(itinerary.keys())
    if start_time:
        first_timestamp_index = all_itinerary_timestamps.index(start_time)
        all_itinerary_timestamps = all_itinerary_timestamps[first_timestamp_index:]

    timestamp = all_itinerary_timestamps.pop(0)
    simulation_dt = _get_datetime(timestamp)
    next_run = datetime.now()
    start = datetime.now()
    simulation_difference = start - simulation_dt
    print("**** Replaying traffic... ****")
    while True:
        if datetime.now() < next_run:
            # It's not time to run the next timestamp in the itinerary yet, so hold off
            time.sleep(0.1)
            continue
        print()
        print("Replaying %s (%s pageviews) at %s" % \
            (itinerary[timestamp]['timestamp'], 
            itinerary[timestamp]['total_pageviews'],
            datetime.now())
        )
        requests = itinerary[timestamp]['itinerary']
        request_tasks = []
        for request in requests:
            task = asyncio.ensure_future(
                run_request(request_func=request_func, request=request, seconds=59)
            )
            request_tasks.append(task)
        loop.run_until_complete(asyncio.wait(request_tasks))
        # What's the next timestamp we need to move on to?
        try:
            next_timestamp = all_itinerary_timestamps.pop(0)
        except IndexError:
            break
        # When should we start running the itinerary for the next timestamp?
        timestamp = next_timestamp
        next_timestamp_dt = _get_datetime(next_timestamp)
        next_run = next_timestamp_dt + simulation_difference
    print("**** Done! ****")

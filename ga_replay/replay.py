import csv, time, requests, os
from datetime import datetime, timedelta
from collections import OrderedDict

from ga_replay.analytics import analytics
import config

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)

def _write_itinerary(itinerary, outfile_path):
    """
    Write itinerary to CSV file.
    """
    with open(outfile_path, "wt") as f:
        writer = csv.writer(f)
        writer.writerows(itinerary)
    
def get_itinerary(start, end, sites, outfile_path=None, extra_dimensions=[]):
    """
    Generate a requests itinerary CSV, given a start date, end date, file path
    and extra dimensions.  The itinerary is generated by grabbing the requests
    logged in historical google analytics data between the dates provided.

    This will generate a CSV of format:
        `HOUR,MINUTE,SITE_DOMAIN,PATH,[extra_dimensions],PAGEVIEWS`

    Args:
        * `start` - `date` - the date for the itinerary to begin
        * `end` - `date` - the date for the itinerary to end
        * `sites` - `iterable` - iterable of site domain strings
        * `outfile_path` - `string` - file path of the CSV to write to
        * `extra_dimensions` - `iterable` - iterable of additional GA dimensions
            to request
    """
    if not outfile_path:
        outfile_path = os.path.join(PROJECT_ROOT, "itineraries", "itinerary.csv")
    site_itineraries = {}
    for site in sites:
        ga_id = config.GA_SITES[site]
        print("**** Grabbing itinerary for %s ****" % site)
        site_itinerary = analytics.get_itinerary(start=start, end=end, 
            ga_id=ga_id, extra_dimensions=extra_dimensions)
        site_itineraries[site] = site_itinerary
        print("**** DONE ****")
    print("**** Flattening site itineraries ****")
    flat_itinerary = []
    for site, itinerary in site_itineraries.items():
        for row in itinerary:
            # Transpose to format:
            # [hour, minute, site, path, extra_dimensions*, pageviews] 
            flat_row = [row[1], row[2], site, row[0], ]
            flat_row.extend(row[3:])
            flat_itinerary.append(flat_row)
    print("**** DONE ****")
    print("**** Sorting itinerary by request time ****")
    flat_itinerary.sort(key=lambda row: row[0] + row[1] + row[3])
    print("**** DONE ****")
    print("**** Writing final itinerary ****")
    _write_itinerary(flat_itinerary, outfile_path)
    print("**** DONE ****")

def dummy_request(domain, path, extra_dimensions=[]):
    print("Requesting %s %s %s" % (domain, path, extra_dimensions))

def simple_request(domain, path, extra_dimensions):
    url = "http://%s%s" % (domain, path)
    requests.get(url)

def analytics_request(domain, path, extra_dimensions=[]):
    """
    Simulate an analytics request for our traffic.

    This is pretty specific for a proprietary analytics platform...
    """
    analytics_host = config.ANALYTICS_HOST
    url = "http://%s/record_pageview/" % analytics_host
    data = {'path': path, 'site': domain, 'referrer': extra_dimensions[0]}
    requests.post(url, data=data)

REQUEST_FUNCTIONS = {
    "dummy": dummy_request,
    "simple": simple_request,
    "analytics": analytics_request,
}

def _load_itinerary(itinerary_path):
    flat_itinerary = []
    with open(itinerary_path, "rt") as f:
        reader = csv.reader(f)
        flat_itinerary = list(reader)
    itinerary = OrderedDict({})
    for row in flat_itinerary:
        key = int(row[0] + row[1])
        try:
            itinerary[key].append(row)
        except KeyError:
            itinerary[key] = [row]
    return itinerary

# TODO: Make this asynchronous. Maybe using this approach:
#   http://pawelmhm.github.io/asyncio/python/aiohttp/2016/04/22/asyncio-aiohttp.html
#   Right now, this is fast enough for our purposes though...  Still huge waits
#   between minutes even for an inventory with few thousand requests per min..
def simulate_from_itinerary(itinerary_path, request_func=dummy_request, start_time=None):
    """
    Run the network requests in a given itinerary to replay traffic.

    Args:
        * `itinerary_path` - `string` - the path to the itinerary CSV file to replay
        * `[request_func]` - `function` - the function to use when making a request
        * `[start_time]` - `string` - string of format "HHMM" to indicate 
            what timestamp to start replaying the itinerary from
    """
    itinerary = _load_itinerary(itinerary_path)
    all_itinerary_timestamps = list(itinerary.keys())
    if start_time:
        start_time = int(start_time)
        first_timestamp_index = all_itinerary_timestamps.index(start_time)
        all_itinerary_timestamps = all_itinerary_timestamps[first_timestamp_index:]
    timestamp = all_itinerary_timestamps.pop(0)
    next_run = datetime.now()
    print("**** Replaying traffic... ****")
    while True:
        if datetime.now() < next_run:
            # It's not time to run the next timestamp in the itinerary yet, so hold off
            time.sleep(1)
            continue
        start = datetime.now()
        requests = itinerary[timestamp]
        for request in requests:
            pageviews = int(request[-1])
            # For each request in the itinerary, simulate the number of requests
            #   logged by `pageviews`
            for i in range(0, pageviews):
                request_func(domain=request[2], path=request[3], extra_dimensions=request[4:-1])
        # What's the next timestamp we need to move on to?
        try:
            next_timestamp = all_itinerary_timestamps.pop(0)
        except IndexError:
            break
        minutes_passed = next_timestamp - timestamp
        # When should we start running the itinerary for the next timestamp?
        next_run = start + timedelta(minutes=minutes_passed)
        timestamp = next_timestamp
    print("**** Done! ****")
